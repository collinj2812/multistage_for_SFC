{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd081c7e-b6ea-4b3f-a123-dc4127b5deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./training')\n",
    "sys.path.append('./training_data')\n",
    "import train_standard_NN\n",
    "import train_BLL\n",
    "import train_CQR\n",
    "import save\n",
    "from data_class import DataClass\n",
    "from simulation_evaluation import simulation_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd26e838-6015-415f-bf3b-de4125fd0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data set\n",
    "training_name = './training data/training.xlsx'\n",
    "test_name = './training data/test.xlsx'\n",
    "\n",
    "# load data\n",
    "training_data_dict, training_meta_data = save.read_excel(training_name)\n",
    "test_data_dict, meta_data_test = save.read_excel(test_name)\n",
    "\n",
    "# define keys from data sets which should be used for training\n",
    "keys_states = ['T_PM', 'T_TM', 'c', 'd10', 'd50', 'd90']\n",
    "keys_inputs = ['mf_PM', 'mf_TM', 'Q_g', 'w_crystal']\n",
    "\n",
    "# define lag parameter l of NARX\n",
    "l = 4\n",
    "\n",
    "# define training parameters (rest will be different for different methods for best results in each case)\n",
    "n_neurons = 30\n",
    "\n",
    "# test data dataclass\n",
    "test_data = DataClass(test_data_dict, keys_states, keys_inputs, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e2e4f-c625-485e-aa69-abc5377ab017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smcojohn\\AppData\\Local\\miniconda3\\envs\\stochastic_sfc\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 0.11120272100575872, Val Loss: 0.09006242570318994, LR: 0.01\n",
      "Epoch 11/2000, Train Loss: 0.10072238187956098, Val Loss: 0.09849921099034845, LR: 0.01\n",
      "Epoch 21/2000, Train Loss: 0.10147825716484661, Val Loss: 0.08925579682846738, LR: 0.01\n",
      "Epoch 31/2000, Train Loss: 0.10163407775693988, Val Loss: 0.08862765180836817, LR: 0.01\n",
      "Epoch 41/2000, Train Loss: 0.10051058370959157, Val Loss: 0.08978080661718253, LR: 0.01\n",
      "Epoch 51/2000, Train Loss: 0.10175988284253633, Val Loss: 0.08955806920862501, LR: 0.01\n",
      "Epoch 61/2000, Train Loss: 0.10136480726948165, Val Loss: 0.08664353958265797, LR: 0.01\n",
      "Epoch 71/2000, Train Loss: 0.10174758484054511, Val Loss: 0.08996615945628494, LR: 0.01\n",
      "Epoch 81/2000, Train Loss: 0.10030646623108287, Val Loss: 0.09599922844179117, LR: 0.01\n"
     ]
    }
   ],
   "source": [
    "# train standard NN\n",
    "training_data_NN = DataClass(training_data_dict, keys_states, keys_inputs, l)\n",
    "\n",
    "model_NN = train_standard_NN.Approximate(training_data_NN, training_meta_data)\n",
    "model_NN.setup(n_neurons=n_neurons, n_epochs=2000, learning_rate=0.01, weight_decay=1e-4, patience=50, lr_scheduler_factor=0.5)\n",
    "model_NN.train()\n",
    "# generate symbolic casadi function\n",
    "model_NN.get_casadi_model()\n",
    "# save model\n",
    "model_NN.save('./data based models/NN_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b714cf88-9db5-4d07-9c45-14813e3e6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test NN model\n",
    "simulation_evaluation(test_data.states, test_data.inputs, model_NN, states=len(keys_states), data_test=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9bd764-6c35-4f90-8529-435b7b5aa869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train CQR model\n",
    "training_data_CQR = DataClass(training_data_dict, keys_states, keys_inputs, l,  split_in_three=True)  # different because of needed calibration dataset\n",
    "\n",
    "# define miscoverage rate\n",
    "alpha = 0.05\n",
    "quantiles = [alpha / 2, 1 - alpha / 2]\n",
    "\n",
    "model_CQR = train_CQR.Approximate(training_data_CQR, quantiles, alpha, training_meta_data)\n",
    "model_CQR.setup(n_neurons_mean=n_neurons, n_neurons_quantiles=10, batch_size=32, n_epochs_mean=2000,\n",
    "                n_epochs_quantiles=2000, learning_rate=0.001, weight_decay_MSE=2e-5, weight_decay_quantiles=2e-5,\n",
    "                patience_MSE=10, patience_quantiles=10, lr_scheduler_factor_MSE=0.5,\n",
    "                lr_scheduler_factor_quantiles=0.5)\n",
    "model_CQR.train()\n",
    "# generate symbolic casadi function\n",
    "model_CQR.get_casadi_model()\n",
    "# save model\n",
    "model_CQR.save('./data based models/CQR_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4908ad0-eb73-448a-8ac0-5ccea77101e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test CQR model\n",
    "# note that the coverage value is only senseful for prediction models and not for simulation models as here\n",
    "simulation_evaluation(test_data.states, test_data.inputs, model_CQR, states=len(keys_states), data_test=test_data, **{'cqr':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd26f4-5747-4fd5-a8be-02107979aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train BLL model\n",
    "training_data_BLL = DataClass(training_data_dict, keys_states, keys_inputs, l)\n",
    "\n",
    "model_BLL = train_BLL.Approximate(training_data_BLL, training_meta_data)\n",
    "model_BLL.setup(n_neurons=n_neurons, n_epochs=2000, learning_rate=0.004)\n",
    "model_BLL.train()\n",
    "# generate symbolic casadi function\n",
    "model_BLL.get_casadi_model()\n",
    "# save model\n",
    "model_BLL.save('./data based models/BLL_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e986575-c58c-4f58-af6c-f8a5b5f0b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test BLL model\n",
    "simulation_evaluation(test_data.states, test_data.inputs, model_BLL, states=len(keys_states), data_test=test_data, **{'bll': model_BLL.std_with_noise})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
